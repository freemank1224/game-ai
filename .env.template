# 服务端口配置
FASTAPI_PORT=8000
VITE_PORT=5173

# Ollama配置（本地LLM）
OLLAMA_ENDPOINT=http://localhost:11434
OLLAMA_API_ENDPOINT=${OLLAMA_ENDPOINT}/api/generate
OLLAMA_MODEL=llama2

# ComfyUI配置
COMFY_UI_ENDPOINT=http://localhost:8188
COMFY_UI_API_ENDPOINT=${COMFY_UI_ENDPOINT}/api/predict
COMFY_UI_WS_ENDPOINT=${COMFY_UI_ENDPOINT}/ws

# FastAPI后端配置
BACKEND_ENDPOINT=http://localhost:${FASTAPI_PORT}
BACKEND_UPLOAD_ENDPOINT=${BACKEND_ENDPOINT}/upload

# 前端环境变量（供Vite使用）
VITE_BACKEND_URL=${BACKEND_ENDPOINT}
VITE_API_ENDPOINT=${BACKEND_UPLOAD_ENDPOINT}
VITE_OLLAMA_ENDPOINT=${OLLAMA_ENDPOINT}
VITE_COMFY_UI_ENDPOINT=${COMFY_UI_ENDPOINT}
